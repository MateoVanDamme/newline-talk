{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing and stacking astrophotography images\n",
    "\n",
    "As a first step we will process a single image using common image processing operations. After that the same operations will be ran on a multitude of images to show the impact on noise. Finally the results will be aggregated in an mp4 image. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Specify the path to the image\n",
    "image_path = r\"E:\\Astronomie\\Images\\Nebulas\\Orion Nebula\\Orion 11 feb 2020\\Image data\\JPEG\\IMG_6407.JPG\"\n",
    "\n",
    "def read_image(path): \n",
    "    # Load the image\n",
    "    image = cv2.imread(path)\n",
    "\n",
    "    # Check if the image was loaded\n",
    "    if image is not None:\n",
    "        print(\"Image imported\")\n",
    "    else:\n",
    "        raise FileNotFoundError(\"Image not found or failed to load.\")\n",
    "    return image\n",
    "\n",
    "# Load the image\n",
    "image = read_image(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(\"Current working directory:\", os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "def display_image(image, dimensions = (800,800), title=\"Untitled\"):    \n",
    "    resized_image = cv2.resize(image, dimensions)\n",
    "    # Convert BGR to RGB for correct color display in matplotlib\n",
    "    resized_image_rgb = cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Display the resized image using matplotlib\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(resized_image_rgb)\n",
    "    plt.title(title)\n",
    "    plt.axis('off')  # Hide the axes for a cleaner display\n",
    "    save_path = os.path.join(os.getcwd(), \"Images\", f\"{title}.png\")\n",
    "    plt.savefig(save_path, bbox_inches='tight')  # Save the plot\n",
    "    plt.show()\n",
    "    print(f\"Image saved to: {save_path}\")\n",
    "\n",
    "\n",
    "display_image(image, (800,600), \"Original image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop(image, center, dimensions): \n",
    "    center_x, center_y = center\n",
    "    width, height = dimensions\n",
    "    \n",
    "    x_start = center_x - width // 2\n",
    "    y_start = center_y - height // 2\n",
    "    x_end = center_x + width // 2\n",
    "    y_end = center_y + height // 2\n",
    "    return image[y_start:y_end, x_start:x_end]; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Center of the crop area\n",
    "center = (3140, 2290)\n",
    "\n",
    "# Width and height of the crop area\n",
    "dimensions = (1500, 1500)\n",
    "\n",
    "# Calculate cropping boundaries using the center point\n",
    "cropped_image = crop(image, center, dimensions)\n",
    "# Resize the image to 800x600\n",
    "\n",
    "display_image(cropped_image, (800,800), \"Cropped image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the image into its RGB components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_channel, g_channel, r_channel = cv2.split(cropped_image)\n",
    "\n",
    "# Create an empty channel with the same dimensions as the input image channels\n",
    "empty_channel = np.zeros_like(b_channel)\n",
    "\n",
    "# Create color versions of each channel\n",
    "blue_image = cv2.merge([b_channel, empty_channel, empty_channel])  \n",
    "green_image = cv2.merge([empty_channel, g_channel, empty_channel])  \n",
    "red_image = cv2.merge([empty_channel, empty_channel, r_channel]) \n",
    "\n",
    "# Move channel to green and create images\n",
    "blue_as_green_image = cv2.merge([empty_channel, b_channel, empty_channel])\n",
    "green_as_green_image = cv2.merge([empty_channel, g_channel, empty_channel])\n",
    "red_as_green_image = cv2.merge([empty_channel, r_channel, empty_channel])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 3x3 grid layout (3 rows, 3 columns)\n",
    "fig, axes = plt.subplots(3, 3, figsize=(15, 15))\n",
    "\n",
    "# Column 1: Original image\n",
    "axes[1, 0].imshow(cv2.cvtColor(cropped_image, cv2.COLOR_BGR2RGB))\n",
    "axes[1, 0].set_title(\"Original Image\")\n",
    "axes[1, 0].axis('off')  # Hide duplicate\n",
    "axes[2, 0].axis('off')  # Hide empty space\n",
    "\n",
    "# Column 2: Channels as their respective colors\n",
    "axes[0, 1].imshow(cv2.cvtColor(blue_image, cv2.COLOR_BGR2RGB))\n",
    "axes[0, 1].set_title(\"Blue Channel (Blue)\")\n",
    "axes[1, 1].imshow(cv2.cvtColor(green_image, cv2.COLOR_BGR2RGB))\n",
    "axes[1, 1].set_title(\"Green Channel (Green)\")\n",
    "axes[2, 1].imshow(cv2.cvtColor(red_image, cv2.COLOR_BGR2RGB))\n",
    "axes[2, 1].set_title(\"Red Channel (Red)\")\n",
    "\n",
    "# Column 3: Channels with green intensity\n",
    "axes[0, 2].imshow(blue_as_green_image, cmap='gray')\n",
    "axes[0, 2].set_title(\"Blue Channel (Green Intensity)\")\n",
    "axes[1, 2].imshow(green_as_green_image, cmap='gray')\n",
    "axes[1, 2].set_title(\"Green Channel (Green Intensity)\")\n",
    "axes[2, 2].imshow(red_as_green_image, cmap='gray')\n",
    "axes[2, 2].set_title(\"Red Channel (Green Intensity)\")\n",
    "\n",
    "# Remove axes for a cleaner display\n",
    "for ax in axes.flat:\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "save_path = os.path.join(os.getcwd(), \"Images\", \"Channel seperation.png\")\n",
    "plt.savefig(save_path, bbox_inches='tight') \n",
    "plt.show()\n",
    "print(f\"Image saved to: {save_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(channel, a, b,): \n",
    "    offset_channel = np.clip(channel + b, 0, 255)\n",
    "    scaled_channel = np.clip(offset_channel * a, 0, 255)\n",
    "    return scaled_channel.astype(np.uint8)\n",
    "\n",
    "def channel_to_green_image(channel): \n",
    "    empty_channel = np.zeros_like(b_channel)\n",
    "    return cv2.merge([empty_channel, channel, empty_channel])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply different scaling and offset to each channel\n",
    "b_transformed = transform(b_channel, 2, -110) #2, -110 \n",
    "g_transformed = transform(g_channel, 2, -140) #2, -140\n",
    "r_transformed = transform(r_channel, 3, -203) #3 -200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to display the original and transformed image with a histogram\n",
    "def display_channel_with_histogram(channel, transformed_channel, channel_name):\n",
    "    # Create the plot\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(10, 10))\n",
    "\n",
    "    # Display the original channel image (as if displayed in the correct color)\n",
    "    axes[0, 0].imshow(cv2.cvtColor(channel_to_green_image(channel), cv2.COLOR_BGR2RGB))\n",
    "    axes[0, 0].set_title(f\"{channel_name} Channel as Green Image\")\n",
    "    axes[0, 0].axis('off')  # Hide axes for the image\n",
    "\n",
    "    # Display the transformed channel image (as if displayed in the correct color)\n",
    "    axes[0, 1].imshow(cv2.cvtColor(channel_to_green_image(transformed_channel), cv2.COLOR_BGR2RGB))\n",
    "    axes[0, 1].set_title(f\"{channel_name} Transformed as Green Image\")\n",
    "    axes[0, 1].axis('off')  # Hide axes for the image\n",
    "\n",
    "    # Plot the green histogram for the original channel\n",
    "    axes[1, 0].bar(np.arange(256), cv2.calcHist([channel], [0], None, [256], [0, 256]).flatten(), width=1.0, color='green')\n",
    "    axes[1, 0].set_xlim([0, 256])\n",
    "    axes[1, 0].set_title(f'{channel_name} Channel Histogram')\n",
    "\n",
    "    # Plot the green histogram for the transformed channel\n",
    "    axes[1, 1].bar(np.arange(256), cv2.calcHist([transformed_channel], [0], None, [256], [0, 256]).flatten(), width=1.0, color='green')\n",
    "    axes[1, 1].set_xlim([0, 256])\n",
    "    axes[1, 1].set_title(f'{channel_name} Transformed Histogram')\n",
    "\n",
    "    # Adjust layout to prevent overlap\n",
    "    plt.tight_layout()\n",
    "    save_path = os.path.join(os.getcwd(), \"Images\", f'{channel_name} Channel transformation.png')\n",
    "    plt.savefig(save_path, bbox_inches='tight') \n",
    "    plt.show()\n",
    "\n",
    "display_channel_with_histogram(b_channel, b_transformed, \"Blue\")\n",
    "display_channel_with_histogram(g_channel, g_transformed, \"Green\")\n",
    "display_channel_with_histogram(r_channel, r_transformed, \"Red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All channels at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def plot_channel_histograms(original_image, transformed_image):\n",
    "    # Split original and transformed images into B, G, R channels\n",
    "    original_channels = cv2.split(original_image)\n",
    "    transformed_channels = cv2.split(transformed_image)\n",
    "    \n",
    "    # Calculate histograms for original channels\n",
    "    original_counts = [cv2.calcHist([channel], [0], None, [256], [0, 256]).flatten() for channel in original_channels]\n",
    "    \n",
    "    # Calculate histograms for transformed channels\n",
    "    transformed_counts = [cv2.calcHist([channel], [0], None, [256], [0, 256]).flatten() for channel in transformed_channels]\n",
    "\n",
    "    # Pixel intensity values from 0 to 255\n",
    "    x = np.arange(256)\n",
    "\n",
    "    # Set up plot\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    \n",
    "    # Colors and labels for channels\n",
    "    colors = ['blue', 'green', 'red']\n",
    "    labels = [\"Blue\", \"Green\", \"Red\"]\n",
    "\n",
    "    # Plot original channels\n",
    "    for i, color in enumerate(colors):\n",
    "        axes[0].bar(x, original_counts[i], color=color, alpha=0.5, width=1.0, label=labels[i])\n",
    "    axes[0].set_title(\"Channels - Before Transformation\")\n",
    "    axes[0].set_xlabel(\"Pixel Intensity\")\n",
    "    axes[0].set_ylabel(\"Frequency\")\n",
    "    axes[0].set_xlim(0, 255)\n",
    "    axes[0].legend()\n",
    "\n",
    "    # Plot transformed channels\n",
    "    for i, color in enumerate(colors):\n",
    "        axes[1].bar(x, transformed_counts[i], color=color, alpha=0.5, width=1.0, label=labels[i])\n",
    "    axes[1].set_title(\"Channels - After Transformation\")\n",
    "    axes[1].set_xlabel(\"Pixel Intensity\")\n",
    "    axes[1].set_ylabel(\"Frequency\")\n",
    "    axes[1].set_xlim(0, 255)\n",
    "    axes[1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    save_path = os.path.join(os.getcwd(), \"Images\", f'Channel transformation together.png')\n",
    "    plt.savefig(save_path, bbox_inches='tight') \n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Merge the channels back into a single image\n",
    "transformed_image = cv2.merge((b_transformed, g_transformed, r_transformed))\n",
    "\n",
    "plot_channel_histograms(cropped_image, transformed_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "display_image(transformed_image, (800,800), \"Transformed image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking multiple images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing a single image in one go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def list_jpg_images(directory):\n",
    "    jpg_image_names = []\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.lower().endswith('.jpg'):\n",
    "                jpg_image_names.append(os.path.join(root, file))\n",
    "    return jpg_image_names\n",
    "\n",
    "# Example usage\n",
    "image_path = r\"E:\\Astronomie\\Images\\Nebulas\\Orion Nebula\\Orion 11 feb 2020\\Image data\\JPEG\"\n",
    "jpg_image_names = list_jpg_images(image_path)\n",
    "print(jpg_image_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def color_enhance(image, center, dimensions, b_params, g_params, r_params):\n",
    "    # Crop the image\n",
    "    cropped_image = crop(image, center, dimensions)\n",
    "    \n",
    "    # Split the image into color channels\n",
    "    b_channel, g_channel, r_channel = cv2.split(cropped_image)\n",
    "    \n",
    "    \n",
    "    # Apply transformations to each channel\n",
    "    b_transformed = transform(b_channel, *b_params)\n",
    "    g_transformed = transform(g_channel, *g_params)\n",
    "    r_transformed = transform(r_channel, *r_params)\n",
    "    \n",
    "    # Merge the channels back into a single image\n",
    "    transformed_image = cv2.merge((b_transformed, g_transformed, r_transformed))\n",
    "    \n",
    "    return transformed_image\n",
    "\n",
    "# Parameters\n",
    "center = (3140, 2290)\n",
    "dimensions = (1500, 1500)\n",
    "b_params = [2, -110]\n",
    "g_params = [2, -140]\n",
    "r_params = [3, -203]\n",
    "\n",
    "# Process the image\n",
    "processed_image = color_enhance(image, center, dimensions, b_params, g_params, r_params)\n",
    "\n",
    "display_image(processed_image, (800,800), \"Transformed image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclid_transform(image, dx, dy, angle):\n",
    "    # Get the dimensions of the image\n",
    "    (height, width) = image.shape[:2]\n",
    "\n",
    "    # Calculate the center of the image (pivot for rotation)\n",
    "    center = (width // 2, height // 2)\n",
    "\n",
    "    # Create the rotation matrix with the given angle\n",
    "    rotation_matrix = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "\n",
    "    # Add translation values (dx, dy) to the transformation matrix\n",
    "    rotation_matrix[0, 2] += dx\n",
    "    rotation_matrix[1, 2] += dy\n",
    "\n",
    "    # Apply the affine transformation (rotation + translation)\n",
    "    transformed_image = cv2.warpAffine(image, rotation_matrix, (width, height))\n",
    "\n",
    "    return transformed_image\n",
    "\n",
    "rotated_image = euclid_transform(processed_image, 0, 0, 10)\n",
    "display_image(rotated_image, (800,800), \"Transformed image\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file with semicolon as delimiter\n",
    "df = pd.read_csv('stacking.csv', delimiter=';')\n",
    "\n",
    "# Combine 'Path' and 'File' columns to create a full path to each image\n",
    "df['FullPath'] = df['Path'] + '/' + df['File']\n",
    "\n",
    "# Select only the necessary columns and make a copy\n",
    "filtered_df = df[['FullPath', 'dX', 'dY', 'Angle']].copy()\n",
    "\n",
    "# Remove the ° symbol, convert 'Angle' to float\n",
    "filtered_df['Angle'] = filtered_df['Angle'].str.replace('°', '').astype(float)\n",
    "\n",
    "# Display the modified DataFrame\n",
    "print(filtered_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = filtered_df['FullPath'].iloc[:2]\n",
    "\n",
    "# Read the images from the first 2 lines of the DataFrame\n",
    "good_images = [read_image(img_path) for img_path in image_paths]\n",
    "\n",
    "# Calculate the average image\n",
    "average_image = np.mean(good_images, axis=0).astype(np.uint8)\n",
    "\n",
    "# Assuming `process_image` and `displayImage` are your functions for processing and displaying\n",
    "processed_image = color_enhance(average_image, center, dimensions, b_params, g_params, r_params)\n",
    "\n",
    "# Display the processed image\n",
    "display_image(processed_image, (800, 800), \"Transformed image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.cloudynights.com/topic/772997-deepskystacker-saving-aligned-images-individually/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
